{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3A_99.28_Achieved.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishwak2k1/EIP3.0-Batch5/blob/master/3A_99_28_Achieved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "tnWOpF5ejsm8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uinU8WvtjuRw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, GlobalAveragePooling2D, DepthwiseConv2D\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Convolution1D, SeparableConvolution2D, AveragePooling2D, BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import Adadelta, Adagrad, Adam, SGD\n",
        "\n",
        "from keras.datasets import mnist\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NI9q-Bugj1Vf",
        "colab_type": "code",
        "outputId": "40f40c34-2a3b-4a81-ceba-8d96e87defb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yUAIu_Hfj9l8",
        "colab_type": "code",
        "outputId": "98bb63f0-37a5-4b5e-b518-c05a475f0a0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "cell_type": "code",
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f63004faf98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "RxhcCjPJkEEG",
        "colab_type": "code",
        "outputId": "66ae64a7-bee7-4e1f-e71d-bcd1cba8377f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "y_train[:10]\n",
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "y_train[:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "g3aukgrENeKa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MODEL 1"
      ]
    },
    {
      "metadata": {
        "id": "W5nTtC5ikaut",
        "colab_type": "code",
        "outputId": "5201cce5-1ef6-4bbb-e97c-71775767cfe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(AveragePooling2D(pool_size=(2, 2), strides=(1, 1),padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(SeparableConvolution2D(32,kernel_size=(1,1),padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) \n",
        "model.add(Convolution2D(10, 4))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_53 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_53 (Batc (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_40 (Separab (None, 10, 10, 32)        1344      \n",
            "_________________________________________________________________\n",
            "batch_normalization_54 (Batc (None, 10, 10, 32)        128       \n",
            "_________________________________________________________________\n",
            "separable_conv2d_41 (Separab (None, 8, 8, 32)          1344      \n",
            "_________________________________________________________________\n",
            "batch_normalization_55 (Batc (None, 8, 8, 32)          128       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_14 (Averag (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_42 (Separab (None, 4, 4, 32)          1088      \n",
            "_________________________________________________________________\n",
            "batch_normalization_56 (Batc (None, 4, 4, 32)          128       \n",
            "_________________________________________________________________\n",
            "conv2d_55 (Conv2D)           (None, 4, 4, 10)          330       \n",
            "_________________________________________________________________\n",
            "conv2d_56 (Conv2D)           (None, 1, 1, 10)          1610      \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 15,796\n",
            "Trainable params: 15,540\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0tjTyUrgkeGx",
        "colab_type": "code",
        "outputId": "9b35bfc4-010d-4c77-9355-09fb3990a9ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7345
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=Adam(lr=0.0012),\n",
        "             metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=512, nb_epoch=200, verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.5034 - acc: 0.8580\n",
            "Epoch 2/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0952 - acc: 0.9719\n",
            "Epoch 3/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0663 - acc: 0.9802\n",
            "Epoch 4/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0546 - acc: 0.9834\n",
            "Epoch 5/200\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0444 - acc: 0.9865\n",
            "Epoch 6/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0389 - acc: 0.9879\n",
            "Epoch 7/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0344 - acc: 0.9896\n",
            "Epoch 8/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0311 - acc: 0.9906\n",
            "Epoch 9/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0292 - acc: 0.9911\n",
            "Epoch 10/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.0252 - acc: 0.9925\n",
            "Epoch 11/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0233 - acc: 0.9926\n",
            "Epoch 12/200\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0226 - acc: 0.9929\n",
            "Epoch 13/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0203 - acc: 0.9936\n",
            "Epoch 14/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0188 - acc: 0.9940\n",
            "Epoch 15/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.0167 - acc: 0.9948\n",
            "Epoch 16/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0155 - acc: 0.9950\n",
            "Epoch 17/200\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0155 - acc: 0.9954\n",
            "Epoch 18/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.0137 - acc: 0.9956\n",
            "Epoch 19/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0138 - acc: 0.9954\n",
            "Epoch 20/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0137 - acc: 0.9956\n",
            "Epoch 21/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.0098 - acc: 0.9971\n",
            "Epoch 22/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0101 - acc: 0.9970\n",
            "Epoch 23/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.0091 - acc: 0.9973\n",
            "Epoch 24/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0085 - acc: 0.9971\n",
            "Epoch 25/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0075 - acc: 0.9978\n",
            "Epoch 26/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0081 - acc: 0.9975\n",
            "Epoch 27/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0061 - acc: 0.9981\n",
            "Epoch 28/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0073 - acc: 0.9975\n",
            "Epoch 29/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0060 - acc: 0.9982\n",
            "Epoch 30/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0059 - acc: 0.9982\n",
            "Epoch 31/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.0048 - acc: 0.9987\n",
            "Epoch 32/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0043 - acc: 0.9989\n",
            "Epoch 33/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0048 - acc: 0.9986\n",
            "Epoch 34/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0058 - acc: 0.9982\n",
            "Epoch 35/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0073 - acc: 0.9972\n",
            "Epoch 36/200\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0066 - acc: 0.9977\n",
            "Epoch 37/200\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0065 - acc: 0.9977\n",
            "Epoch 38/200\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0057 - acc: 0.9983\n",
            "Epoch 39/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0067 - acc: 0.9977\n",
            "Epoch 40/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.0042 - acc: 0.9986\n",
            "Epoch 41/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0036 - acc: 0.9989\n",
            "Epoch 42/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0026 - acc: 0.9993\n",
            "Epoch 43/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0017 - acc: 0.9997\n",
            "Epoch 44/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0011 - acc: 0.9999\n",
            "Epoch 45/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 6.6631e-04 - acc: 1.0000\n",
            "Epoch 46/200\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 5.0948e-04 - acc: 1.0000\n",
            "Epoch 47/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 4.7467e-04 - acc: 1.0000\n",
            "Epoch 48/200\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 4.5044e-04 - acc: 1.0000\n",
            "Epoch 49/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 4.3595e-04 - acc: 1.0000\n",
            "Epoch 50/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 4.2219e-04 - acc: 1.0000\n",
            "Epoch 51/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 4.1499e-04 - acc: 1.0000\n",
            "Epoch 52/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.9763e-04 - acc: 1.0000\n",
            "Epoch 53/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 3.8729e-04 - acc: 1.0000\n",
            "Epoch 54/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.8286e-04 - acc: 1.0000\n",
            "Epoch 55/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.7589e-04 - acc: 1.0000\n",
            "Epoch 56/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.6720e-04 - acc: 1.0000\n",
            "Epoch 57/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.6049e-04 - acc: 1.0000\n",
            "Epoch 58/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.5919e-04 - acc: 1.0000\n",
            "Epoch 59/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.4708e-04 - acc: 1.0000\n",
            "Epoch 60/200\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 3.4457e-04 - acc: 1.0000\n",
            "Epoch 61/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.3960e-04 - acc: 1.0000\n",
            "Epoch 62/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 3.3542e-04 - acc: 1.0000\n",
            "Epoch 63/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.3272e-04 - acc: 1.0000\n",
            "Epoch 64/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.2672e-04 - acc: 1.0000\n",
            "Epoch 65/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.2274e-04 - acc: 1.0000\n",
            "Epoch 66/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 3.1977e-04 - acc: 1.0000\n",
            "Epoch 67/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.1595e-04 - acc: 1.0000\n",
            "Epoch 68/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.1334e-04 - acc: 1.0000\n",
            "Epoch 69/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.1197e-04 - acc: 1.0000\n",
            "Epoch 70/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.1218e-04 - acc: 1.0000\n",
            "Epoch 71/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.0495e-04 - acc: 1.0000\n",
            "Epoch 72/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 3.0386e-04 - acc: 1.0000\n",
            "Epoch 73/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 3.0075e-04 - acc: 1.0000\n",
            "Epoch 74/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.0109e-04 - acc: 1.0000\n",
            "Epoch 75/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0521 - acc: 0.9878\n",
            "Epoch 76/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0233 - acc: 0.9934\n",
            "Epoch 77/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0089 - acc: 0.9971\n",
            "Epoch 78/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0056 - acc: 0.9980\n",
            "Epoch 79/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0035 - acc: 0.9988\n",
            "Epoch 80/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0022 - acc: 0.9995\n",
            "Epoch 81/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0015 - acc: 0.9999\n",
            "Epoch 82/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0014 - acc: 0.9998\n",
            "Epoch 83/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0011 - acc: 0.9999\n",
            "Epoch 84/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 7.4721e-04 - acc: 1.0000\n",
            "Epoch 85/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 6.2065e-04 - acc: 1.0000\n",
            "Epoch 86/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 5.3225e-04 - acc: 1.0000\n",
            "Epoch 87/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 5.1855e-04 - acc: 1.0000\n",
            "Epoch 88/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 4.8338e-04 - acc: 1.0000\n",
            "Epoch 89/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 4.6683e-04 - acc: 1.0000\n",
            "Epoch 90/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 4.4730e-04 - acc: 1.0000\n",
            "Epoch 91/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 4.2169e-04 - acc: 1.0000\n",
            "Epoch 92/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 4.1680e-04 - acc: 1.0000\n",
            "Epoch 93/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 4.0058e-04 - acc: 1.0000\n",
            "Epoch 94/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.9138e-04 - acc: 1.0000\n",
            "Epoch 95/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.7978e-04 - acc: 1.0000\n",
            "Epoch 96/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.7611e-04 - acc: 1.0000\n",
            "Epoch 97/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.6416e-04 - acc: 1.0000\n",
            "Epoch 98/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.5562e-04 - acc: 1.0000\n",
            "Epoch 99/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.5386e-04 - acc: 1.0000\n",
            "Epoch 100/200\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 3.4542e-04 - acc: 1.0000\n",
            "Epoch 101/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.3677e-04 - acc: 1.0000\n",
            "Epoch 102/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.3227e-04 - acc: 1.0000\n",
            "Epoch 103/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.2966e-04 - acc: 1.0000\n",
            "Epoch 104/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0270 - acc: 0.9936\n",
            "Epoch 105/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.0212 - acc: 0.9936\n",
            "Epoch 106/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0064 - acc: 0.9978\n",
            "Epoch 107/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0032 - acc: 0.9990\n",
            "Epoch 108/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0015 - acc: 0.9997\n",
            "Epoch 109/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 9.4156e-04 - acc: 1.0000\n",
            "Epoch 110/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 6.5901e-04 - acc: 1.0000\n",
            "Epoch 111/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 5.7823e-04 - acc: 1.0000\n",
            "Epoch 112/200\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 5.0496e-04 - acc: 1.0000\n",
            "Epoch 113/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 4.8200e-04 - acc: 1.0000\n",
            "Epoch 114/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 4.5896e-04 - acc: 1.0000\n",
            "Epoch 115/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 4.4247e-04 - acc: 1.0000\n",
            "Epoch 116/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 4.3090e-04 - acc: 1.0000\n",
            "Epoch 117/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 4.1264e-04 - acc: 1.0000\n",
            "Epoch 118/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.9769e-04 - acc: 1.0000\n",
            "Epoch 119/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.8463e-04 - acc: 1.0000\n",
            "Epoch 120/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.7390e-04 - acc: 1.0000\n",
            "Epoch 121/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.7076e-04 - acc: 1.0000\n",
            "Epoch 122/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.7218e-04 - acc: 1.0000\n",
            "Epoch 123/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.5392e-04 - acc: 1.0000\n",
            "Epoch 124/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.4812e-04 - acc: 1.0000\n",
            "Epoch 125/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.4500e-04 - acc: 1.0000\n",
            "Epoch 126/200\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 3.3813e-04 - acc: 1.0000\n",
            "Epoch 127/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.3212e-04 - acc: 1.0000\n",
            "Epoch 128/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.2746e-04 - acc: 1.0000\n",
            "Epoch 129/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 3.2646e-04 - acc: 1.0000\n",
            "Epoch 130/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.2013e-04 - acc: 1.0000\n",
            "Epoch 131/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 3.1629e-04 - acc: 1.0000\n",
            "Epoch 132/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 3.1510e-04 - acc: 1.0000\n",
            "Epoch 133/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.0937e-04 - acc: 1.0000\n",
            "Epoch 134/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.1855e-04 - acc: 1.0000\n",
            "Epoch 135/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 3.0508e-04 - acc: 1.0000\n",
            "Epoch 136/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.1384e-04 - acc: 1.0000\n",
            "Epoch 137/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.0327e-04 - acc: 1.0000\n",
            "Epoch 138/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 2.9753e-04 - acc: 1.0000\n",
            "Epoch 139/200\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 2.9674e-04 - acc: 1.0000\n",
            "Epoch 140/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.0356 - acc: 0.9915\n",
            "Epoch 141/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0132 - acc: 0.9960\n",
            "Epoch 142/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0063 - acc: 0.9978\n",
            "Epoch 143/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0022 - acc: 0.9994\n",
            "Epoch 144/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0013 - acc: 0.9997\n",
            "Epoch 145/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 8.3037e-04 - acc: 1.0000\n",
            "Epoch 146/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 5.6396e-04 - acc: 1.0000\n",
            "Epoch 147/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 4.9462e-04 - acc: 1.0000\n",
            "Epoch 148/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 4.8086e-04 - acc: 1.0000\n",
            "Epoch 149/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 4.2365e-04 - acc: 1.0000\n",
            "Epoch 150/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 4.1077e-04 - acc: 1.0000\n",
            "Epoch 151/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.9872e-04 - acc: 1.0000\n",
            "Epoch 152/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.9392e-04 - acc: 1.0000\n",
            "Epoch 153/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.7728e-04 - acc: 1.0000\n",
            "Epoch 154/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 3.7171e-04 - acc: 1.0000\n",
            "Epoch 155/200\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 3.6209e-04 - acc: 1.0000\n",
            "Epoch 156/200\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 3.5741e-04 - acc: 1.0000\n",
            "Epoch 157/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.4872e-04 - acc: 1.0000\n",
            "Epoch 158/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.4574e-04 - acc: 1.0000\n",
            "Epoch 159/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.3946e-04 - acc: 1.0000\n",
            "Epoch 160/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 3.3427e-04 - acc: 1.0000\n",
            "Epoch 161/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 3.3060e-04 - acc: 1.0000\n",
            "Epoch 162/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.2623e-04 - acc: 1.0000\n",
            "Epoch 163/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 3.2005e-04 - acc: 1.0000\n",
            "Epoch 164/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 3.1913e-04 - acc: 1.0000\n",
            "Epoch 165/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.1257e-04 - acc: 1.0000\n",
            "Epoch 166/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 3.1276e-04 - acc: 1.0000\n",
            "Epoch 167/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.0738e-04 - acc: 1.0000\n",
            "Epoch 168/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.0547e-04 - acc: 1.0000\n",
            "Epoch 169/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.0358e-04 - acc: 1.0000\n",
            "Epoch 170/200\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 3.0137e-04 - acc: 1.0000\n",
            "Epoch 171/200\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 3.1093e-04 - acc: 1.0000\n",
            "Epoch 172/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 2.9992e-04 - acc: 1.0000\n",
            "Epoch 173/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 2.9747e-04 - acc: 1.0000\n",
            "Epoch 174/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 2.9517e-04 - acc: 1.0000\n",
            "Epoch 175/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.1098e-04 - acc: 1.0000\n",
            "Epoch 176/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 2.9363e-04 - acc: 1.0000\n",
            "Epoch 177/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 2.8980e-04 - acc: 1.0000\n",
            "Epoch 178/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 2.8859e-04 - acc: 1.0000\n",
            "Epoch 179/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 2.8629e-04 - acc: 1.0000\n",
            "Epoch 180/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 2.8630e-04 - acc: 1.0000\n",
            "Epoch 181/200\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 2.8441e-04 - acc: 1.0000\n",
            "Epoch 182/200\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 2.8370e-04 - acc: 1.0000\n",
            "Epoch 183/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 2.8256e-04 - acc: 1.0000\n",
            "Epoch 184/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 2.8141e-04 - acc: 1.0000\n",
            "Epoch 185/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 2.8100e-04 - acc: 1.0000\n",
            "Epoch 186/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 2.8008e-04 - acc: 1.0000\n",
            "Epoch 187/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 2.7925e-04 - acc: 1.0000\n",
            "Epoch 188/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 2.7871e-04 - acc: 1.0000\n",
            "Epoch 189/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 2.7868e-04 - acc: 1.0000\n",
            "Epoch 190/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 2.7777e-04 - acc: 1.0000\n",
            "Epoch 191/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0319 - acc: 0.9930\n",
            "Epoch 192/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0147 - acc: 0.9957\n",
            "Epoch 193/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0037 - acc: 0.9987\n",
            "Epoch 194/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0016 - acc: 0.9996\n",
            "Epoch 195/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 6.7004e-04 - acc: 1.0000\n",
            "Epoch 196/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 4.9046e-04 - acc: 1.0000\n",
            "Epoch 197/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 4.1309e-04 - acc: 1.0000\n",
            "Epoch 198/200\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 3.8909e-04 - acc: 1.0000\n",
            "Epoch 199/200\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 3.7540e-04 - acc: 1.0000\n",
            "Epoch 200/200\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 3.6848e-04 - acc: 1.0000\n",
            "[0.04564153137737867, 0.9908]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EeOj-XnTY0Or",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b3a6f7f0-0f94-40fa-8490-01f4fa3599dc"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.054321200714715995, 0.9906]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AX4VgQYhhEVi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Name : Viswanath K\n",
        "# Email: vishwak2k1@gmail.com\n",
        "# EIP3.0 Batch 5\n",
        "# https://www.youtube.com/watch?v=gmBfb6LNnZs\n",
        "# Learnable Parameters in a Convolutional Neural Network (CNN) explained"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vtFpVadpNHgf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MODEL 2"
      ]
    },
    {
      "metadata": {
        "id": "aP6xQaaYM-o2",
        "colab_type": "code",
        "outputId": "a4e5ba95-e43f-420f-8c39-4ca939bb23a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(SeparableConvolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(SeparableConvolution2D(32, 3, 3, activation='relu'))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2),padding='same'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2),padding='same'))\n",
        "\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) \n",
        "model.add(Convolution2D(10, 4))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "             optimizer='SGD',\n",
        "             metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=1, verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "separable_conv2d_3 (Separabl (None, 26, 26, 32)        73        \n",
            "_________________________________________________________________\n",
            "separable_conv2d_4 (Separabl (None, 24, 24, 32)        1344      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_3 (Average (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_5 (Separabl (None, 10, 10, 32)        1344      \n",
            "_________________________________________________________________\n",
            "separable_conv2d_6 (Separabl (None, 8, 8, 32)          1344      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_4 (Average (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 4, 10)          330       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          1610      \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 6,045\n",
            "Trainable params: 6,045\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 86s 1ms/step - loss: 2.3017 - acc: 0.1119\n",
            "[2.301089622116089, 0.1135]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qHNFur8GNRY1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lf9I2XvuRMC0",
        "colab_type": "code",
        "outputId": "38ab471c-b6ca-40b4-fc16-5f98255bae0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2),padding='same'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "model.add(Convolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2),padding='same'))\n",
        "\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) \n",
        "model.add(Convolution2D(10, 4))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "             optimizer='SGD',\n",
        "             metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=1, verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_5 (Average (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 10, 10, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 8, 8, 32)          9248      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_6 (Average (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 4, 4, 10)          330       \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 1, 1, 10)          1610      \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 30,004\n",
            "Trainable params: 30,004\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 129s 2ms/step - loss: 0.7171 - acc: 0.7616\n",
            "[0.261438225454092, 0.9229]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PDXKSNmtSy0p",
        "colab_type": "code",
        "outputId": "1c425393-8d42-4dfd-99a6-7ac3b7bec1c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2),padding='same'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2),padding='same'))\n",
        "\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) \n",
        "model.add(Convolution2D(10, 4))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "             optimizer='SGD',\n",
        "             metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=1, verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_7 (Average (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 10, 10, 32)        9248      \n",
            "_________________________________________________________________\n",
            "separable_conv2d_7 (Separabl (None, 8, 8, 32)          1344      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_8 (Average (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 4, 4, 10)          330       \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 1, 1, 10)          1610      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 22,100\n",
            "Trainable params: 22,100\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 127s 2ms/step - loss: 4.4112 - acc: 0.1986\n",
            "[14.461155044555664, 0.1028]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I1PUiviUT6e5",
        "colab_type": "code",
        "outputId": "e74e8e9a-46d3-46aa-dbef-af9d090d5d7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2),padding='same'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2),padding='same'))\n",
        "\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) \n",
        "model.add(Convolution2D(10, 4))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "             optimizer='SGD',\n",
        "             metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_101 (Conv2D)          (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_102 (Conv2D)          (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_36 (MaxPooling (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_103 (Conv2D)          (None, 10, 10, 32)        9248      \n",
            "_________________________________________________________________\n",
            "separable_conv2d_26 (Separab (None, 8, 8, 32)          1344      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_104 (Conv2D)          (None, 4, 4, 10)          330       \n",
            "_________________________________________________________________\n",
            "conv2d_105 (Conv2D)          (None, 1, 1, 10)          1610      \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 22,100\n",
            "Trainable params: 22,100\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 20s 327us/step - loss: 1.1219 - acc: 0.6362\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 18s 295us/step - loss: 0.1772 - acc: 0.9472\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 18s 294us/step - loss: 0.1256 - acc: 0.9615\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 18s 295us/step - loss: 0.1042 - acc: 0.9680\n",
            "Epoch 5/10\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.0920 - acc: 0.9721"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_eQ4koTOebGJ",
        "colab_type": "code",
        "outputId": "ed51bc62-d13d-4a0a-8444-725cfab71204",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2),padding='same'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(DepthwiseConv2D(32,kernel_size=(3,3),padding='valid'))\n",
        "model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2),padding='same'))\n",
        "\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) \n",
        "model.add(Convolution2D(10, 4))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "             optimizer='SGD',\n",
        "             metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=1, verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-601f7aed58db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDepthwiseConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeparableConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got multiple values for argument 'kernel_size'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "bcUPILbsNXoU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MODEL 3"
      ]
    },
    {
      "metadata": {
        "id": "kSXJUj7X10lL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "model.add(AveragePooling2D(pool_size=(2, 2), strides=(1, 1),padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
        "model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "#model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) \n",
        "model.add(Convolution2D(10, 7))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oJYHf2CT7Vwq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MODEL using Depthwise 2D Convolution and Batch  Normalization"
      ]
    },
    {
      "metadata": {
        "id": "N1lVYxyMNS1g",
        "colab_type": "code",
        "outputId": "ce0e7e38-aee6-4e45-927d-d72d3a4dd644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(DepthwiseConv2D(depth_multiplier = 1, kernel_size=(3, 3), \n",
        "                          input_shape = (22,22,3), padding = 'valid', strides = (1,1)))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "#model.add(AveragePooling2D(pool_size=(2, 2), strides=(1, 1),padding='same'))\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
        "model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
        "model.add(DepthwiseConv2D(depth_multiplier = 1, kernel_size=(3, 3), \n",
        "                          input_shape = (9,9,3), padding = 'valid', strides = (1,1)))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "#model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "#model.add(SeparableConvolution2D(32,kernel_size=(3,3),padding='valid'))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) \n",
        "model.add(Convolution2D(10, 6))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_57 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 24, 24, 16)        4624      \n",
            "_________________________________________________________________\n",
            "batch_normalization_57 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_1 (Depthwis (None, 22, 22, 16)        160       \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 20, 20, 16)        2320      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_15 (Averag (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_60 (Conv2D)           (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_2 (Depthwis (None, 6, 6, 16)          160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_58 (Batc (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_61 (Conv2D)           (None, 6, 6, 10)          170       \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 1, 1, 10)          3610      \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,812\n",
            "Trainable params: 13,748\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "57dqIDy1NTrb",
        "colab_type": "code",
        "outputId": "526fb0db-d892-4c1b-9c55-ea71a610af5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5526
        }
      },
      "cell_type": "code",
      "source": [
        "#sgd = SGD(lr=0.001)\n",
        "#sgd = optimizer.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "             optimizer=Adam(lr=0.0012),\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=512, nb_epoch=150, verbose=1)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "60000/60000 [==============================] - 12s 207us/step - loss: 0.5162 - acc: 0.8517\n",
            "Epoch 2/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.0813 - acc: 0.9763\n",
            "Epoch 3/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.0546 - acc: 0.9839\n",
            "Epoch 4/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0448 - acc: 0.9870\n",
            "Epoch 5/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0386 - acc: 0.9885\n",
            "Epoch 6/150\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0336 - acc: 0.9898\n",
            "Epoch 7/150\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0287 - acc: 0.9915\n",
            "Epoch 8/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.0261 - acc: 0.9924\n",
            "Epoch 9/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0239 - acc: 0.9926\n",
            "Epoch 10/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0215 - acc: 0.9935\n",
            "Epoch 11/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0200 - acc: 0.9941\n",
            "Epoch 12/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0190 - acc: 0.9940\n",
            "Epoch 13/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0170 - acc: 0.9947\n",
            "Epoch 14/150\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0166 - acc: 0.9949\n",
            "Epoch 15/150\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0142 - acc: 0.9955\n",
            "Epoch 16/150\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0132 - acc: 0.9962\n",
            "Epoch 17/150\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0119 - acc: 0.9966\n",
            "Epoch 18/150\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0117 - acc: 0.9964\n",
            "Epoch 19/150\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0103 - acc: 0.9970\n",
            "Epoch 20/150\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0091 - acc: 0.9975\n",
            "Epoch 21/150\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0099 - acc: 0.9968\n",
            "Epoch 22/150\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0090 - acc: 0.9973\n",
            "Epoch 23/150\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0085 - acc: 0.9975\n",
            "Epoch 24/150\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0082 - acc: 0.9975\n",
            "Epoch 25/150\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0068 - acc: 0.9979\n",
            "Epoch 26/150\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0099 - acc: 0.9968\n",
            "Epoch 27/150\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0054 - acc: 0.9985\n",
            "Epoch 28/150\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0042 - acc: 0.9991\n",
            "Epoch 29/150\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0048 - acc: 0.9988\n",
            "Epoch 30/150\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0040 - acc: 0.9990\n",
            "Epoch 31/150\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0048 - acc: 0.9984\n",
            "Epoch 32/150\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0044 - acc: 0.9987\n",
            "Epoch 33/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0049 - acc: 0.9986\n",
            "Epoch 34/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0074 - acc: 0.9976\n",
            "Epoch 35/150\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0050 - acc: 0.9986\n",
            "Epoch 36/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0034 - acc: 0.9990\n",
            "Epoch 37/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.0032 - acc: 0.9991\n",
            "Epoch 38/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0027 - acc: 0.9994\n",
            "Epoch 39/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.0015 - acc: 0.9998\n",
            "Epoch 40/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0029 - acc: 0.9991\n",
            "Epoch 41/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.0105 - acc: 0.9963\n",
            "Epoch 42/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.0063 - acc: 0.9978\n",
            "Epoch 43/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0034 - acc: 0.9991\n",
            "Epoch 44/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.0016 - acc: 0.9998\n",
            "Epoch 45/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 9.3847e-04 - acc: 1.0000\n",
            "Epoch 46/150\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 5.9284e-04 - acc: 1.0000\n",
            "Epoch 47/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 5.5737e-04 - acc: 1.0000\n",
            "Epoch 48/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 5.2570e-04 - acc: 1.0000\n",
            "Epoch 49/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 4.8150e-04 - acc: 1.0000\n",
            "Epoch 50/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 4.5773e-04 - acc: 1.0000\n",
            "Epoch 51/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 4.4475e-04 - acc: 1.0000\n",
            "Epoch 52/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 4.4019e-04 - acc: 1.0000\n",
            "Epoch 53/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 4.2136e-04 - acc: 1.0000\n",
            "Epoch 54/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 4.1641e-04 - acc: 1.0000\n",
            "Epoch 55/150\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 3.9979e-04 - acc: 1.0000\n",
            "Epoch 56/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.9523e-04 - acc: 1.0000\n",
            "Epoch 57/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.8438e-04 - acc: 1.0000\n",
            "Epoch 58/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.7996e-04 - acc: 1.0000\n",
            "Epoch 59/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.6870e-04 - acc: 1.0000\n",
            "Epoch 60/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.6210e-04 - acc: 1.0000\n",
            "Epoch 61/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.7010e-04 - acc: 1.0000\n",
            "Epoch 62/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.5140e-04 - acc: 1.0000\n",
            "Epoch 63/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 3.4505e-04 - acc: 1.0000\n",
            "Epoch 64/150\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 3.3756e-04 - acc: 1.0000\n",
            "Epoch 65/150\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 3.3791e-04 - acc: 1.0000\n",
            "Epoch 66/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.2818e-04 - acc: 1.0000\n",
            "Epoch 67/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.3084e-04 - acc: 1.0000\n",
            "Epoch 68/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.3005e-04 - acc: 1.0000\n",
            "Epoch 69/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0054 - acc: 0.9988\n",
            "Epoch 70/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.0473 - acc: 0.9886\n",
            "Epoch 71/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0119 - acc: 0.9961\n",
            "Epoch 72/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0050 - acc: 0.9984\n",
            "Epoch 73/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0031 - acc: 0.9993\n",
            "Epoch 74/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0014 - acc: 0.9998\n",
            "Epoch 75/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 8.8564e-04 - acc: 1.0000\n",
            "Epoch 76/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 7.1480e-04 - acc: 1.0000\n",
            "Epoch 77/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 6.3247e-04 - acc: 1.0000\n",
            "Epoch 78/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 5.7914e-04 - acc: 1.0000\n",
            "Epoch 79/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 5.4811e-04 - acc: 1.0000\n",
            "Epoch 80/150\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 5.2560e-04 - acc: 1.0000\n",
            "Epoch 81/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 5.0142e-04 - acc: 1.0000\n",
            "Epoch 82/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 4.6803e-04 - acc: 1.0000\n",
            "Epoch 83/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 4.5490e-04 - acc: 1.0000\n",
            "Epoch 84/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 4.5030e-04 - acc: 1.0000\n",
            "Epoch 85/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 4.4257e-04 - acc: 1.0000\n",
            "Epoch 86/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 4.0997e-04 - acc: 1.0000\n",
            "Epoch 87/150\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 4.0033e-04 - acc: 1.0000\n",
            "Epoch 88/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.9090e-04 - acc: 1.0000\n",
            "Epoch 89/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.9114e-04 - acc: 1.0000\n",
            "Epoch 90/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.9220e-04 - acc: 1.0000\n",
            "Epoch 91/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.6995e-04 - acc: 1.0000\n",
            "Epoch 92/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.6192e-04 - acc: 1.0000\n",
            "Epoch 93/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.5576e-04 - acc: 1.0000\n",
            "Epoch 94/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.4400e-04 - acc: 1.0000\n",
            "Epoch 95/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.4326e-04 - acc: 1.0000\n",
            "Epoch 96/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.3757e-04 - acc: 1.0000\n",
            "Epoch 97/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 3.3360e-04 - acc: 1.0000\n",
            "Epoch 98/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.3067e-04 - acc: 1.0000\n",
            "Epoch 99/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 3.2516e-04 - acc: 1.0000\n",
            "Epoch 100/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.1981e-04 - acc: 1.0000\n",
            "Epoch 101/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 3.1600e-04 - acc: 1.0000\n",
            "Epoch 102/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 3.1733e-04 - acc: 1.0000\n",
            "Epoch 103/150\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 3.1132e-04 - acc: 1.0000\n",
            "Epoch 104/150\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 3.1281e-04 - acc: 1.0000\n",
            "Epoch 105/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.0733e-04 - acc: 1.0000\n",
            "Epoch 106/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 3.0380e-04 - acc: 1.0000\n",
            "Epoch 107/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 3.0010e-04 - acc: 1.0000\n",
            "Epoch 108/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 2.9976e-04 - acc: 1.0000\n",
            "Epoch 109/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 2.9630e-04 - acc: 1.0000\n",
            "Epoch 110/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 2.9697e-04 - acc: 1.0000\n",
            "Epoch 111/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 2.9550e-04 - acc: 1.0000\n",
            "Epoch 112/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 2.9314e-04 - acc: 1.0000\n",
            "Epoch 113/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 2.9018e-04 - acc: 1.0000\n",
            "Epoch 114/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 2.8831e-04 - acc: 1.0000\n",
            "Epoch 115/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 2.9083e-04 - acc: 1.0000\n",
            "Epoch 116/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 2.8965e-04 - acc: 1.0000\n",
            "Epoch 117/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0408 - acc: 0.9908\n",
            "Epoch 118/150\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0150 - acc: 0.9956\n",
            "Epoch 119/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0050 - acc: 0.9983\n",
            "Epoch 120/150\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0023 - acc: 0.9995\n",
            "Epoch 121/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0011 - acc: 0.9998\n",
            "Epoch 122/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 9.1600e-04 - acc: 0.9999\n",
            "Epoch 123/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 5.7189e-04 - acc: 1.0000\n",
            "Epoch 124/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 4.9455e-04 - acc: 1.0000\n",
            "Epoch 125/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 4.6110e-04 - acc: 1.0000\n",
            "Epoch 126/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 4.4016e-04 - acc: 1.0000\n",
            "Epoch 127/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 4.2521e-04 - acc: 1.0000\n",
            "Epoch 128/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 4.0956e-04 - acc: 1.0000\n",
            "Epoch 129/150\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 3.9724e-04 - acc: 1.0000\n",
            "Epoch 130/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.8761e-04 - acc: 1.0000\n",
            "Epoch 131/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.8352e-04 - acc: 1.0000\n",
            "Epoch 132/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.6821e-04 - acc: 1.0000\n",
            "Epoch 133/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.6179e-04 - acc: 1.0000\n",
            "Epoch 134/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.5895e-04 - acc: 1.0000\n",
            "Epoch 135/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 3.5304e-04 - acc: 1.0000\n",
            "Epoch 136/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 3.4784e-04 - acc: 1.0000\n",
            "Epoch 137/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.4118e-04 - acc: 1.0000\n",
            "Epoch 138/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 3.4148e-04 - acc: 1.0000\n",
            "Epoch 139/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.3356e-04 - acc: 1.0000\n",
            "Epoch 140/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 3.3228e-04 - acc: 1.0000\n",
            "Epoch 141/150\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.0168 - acc: 0.9949\n",
            "Epoch 142/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0097 - acc: 0.9968\n",
            "Epoch 143/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0031 - acc: 0.9989\n",
            "Epoch 144/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0021 - acc: 0.9994\n",
            "Epoch 145/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 7.2740e-04 - acc: 1.0000\n",
            "Epoch 146/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 5.1830e-04 - acc: 1.0000\n",
            "Epoch 147/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.9689e-04 - acc: 1.0000\n",
            "Epoch 148/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.7414e-04 - acc: 1.0000\n",
            "Epoch 149/150\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 3.7455e-04 - acc: 1.0000\n",
            "Epoch 150/150\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 3.5952e-04 - acc: 1.0000\n",
            "[0.03290008217437573, 0.9928]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7W10d1hXT6UE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}